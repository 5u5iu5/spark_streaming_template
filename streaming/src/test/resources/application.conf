
application {

  process = [
    {name = "process1", description = "des_process1"},
  ]

  topic = [
    {name = "topicToConsume", typeOf = "suscribe", description = "des_topicToConsume", schema = "xxx_stream", max_message_bytes = 9999, format = "json"},
    {name = "topicToPublish", typeOf = "publish", description = "des_topicToPublish", schema = "xxx_stream", max_message_bytes = 9999, format = "avro"}
  ]

  parameters = {
    sparkMaster="local[2]"
    kuduHost="localhost"
    kafkaConsumerGroup="test-gid"
    kafkaServers="localhost:9092"
    kafkaProducerServers="localhost:9092"
    kafkaWithKerberos=false
    schemaRegistryURL="http://localhost:8081"
    sparkBatchDuration=60
    kuduMaxNumberOfColumns=8
    gracefulShutdownFile="sparkStreaming.dontRemove.file"
    auditUser="test"
    timeZone="Europe/Madrid",
    dateFormat="yyyy-MM-dd HH:mm:ss"
  }

}